{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9059cc5",
   "metadata": {},
   "source": [
    "# 전처리 과정\n",
    "\n",
    "- RMSE : 26185.4795\n",
    "- 데이터 : train_csv, test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35418d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 후\n",
    "# 전처리 위한 데이터셋 합치기\n",
    "\n",
    "train['data'] = 0\n",
    "test['data'] = 1\n",
    "concat = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이름 바꾸기\n",
    "\n",
    "concat = concat.rename(columns={'전용면적(㎡)':'전용면적'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27417357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본번, 부번의 경우 float로 되어있지만 범주형 변수의 의미를 가지므로 object(string) 형태로 바꾸기\n",
    "concat_select['본번'] = concat_select['본번'].astype('str')\n",
    "concat_select['부번'] = concat_select['부번'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f8105",
   "metadata": {},
   "source": [
    "### 결측치 탐색 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 탐색 후 결측률 보기\n",
    "# 이후에 의미 없는 값들 찾아서 채우기\n",
    "# 위 처럼 아무 의미도 갖지 않는 칼럼은 결측치와 같은 역할을 하므로, np.nan으로 채워 결측치로 인식시킴\n",
    "\n",
    "concat['도로명'] = concat['도로명'].replace(' ', np.nan)\n",
    "concat['등기신청일자'] = concat['등기신청일자'].replace(' ', np.nan)\n",
    "concat['거래유형'] = concat['거래유형'].replace('-', np.nan)\n",
    "concat['중개사소재지'] = concat['중개사소재지'].replace('-', np.nan)\n",
    "concat['k-시행사'] = concat['k-시행사'].replace('.', np.nan)\n",
    "concat['k-시행사'] = concat['k-시행사'].replace('-', np.nan)\n",
    "concat['k-홈페이지'] = concat['k-홈페이지'].replace('없음', np.nan)\n",
    "concat['k-홈페이지'] = concat['k-홈페이지'].replace('.', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(concat.shape[0] * 0.8) = 902475.2000000001\n",
    "# 결측값이 80%이상인(Null값이 90만개 이상) 칼럼은 삭제\n",
    "print('* 결측치가 90만개 이하인 변수들 :', list(concat.columns[concat.isnull().sum() <= 900000]))     # 남겨질 변수들은 아래와 같습니다.\n",
    "print('* 결측치가 90만개 이상인 변수들 :', list(concat.columns[concat.isnull().sum() >= 900000]))\n",
    "\n",
    "# 결측치 90만개 이상인 값과 이하지만 필요없는 것 제외\n",
    "# 필요없어 보이는 것 : k-전화번호, k-팩스번호, 사용허가여부, 관리비 업로드, k-수정일자\n",
    "valid_cols = concat.columns[concat.isnull().sum() <= 900000]\n",
    "exclude_cols = ['k-전화번호', 'k-팩스번호', '사용허가여부', '관리비 업로드', 'k-수정일자']\n",
    "\n",
    "select = [col for col in valid_cols if col not in exclude_cols]\n",
    "concat_select = concat[select]\n",
    "\n",
    "concat.shape, concat_select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저, 연속형 변수와 범주형 변수를 위 info에 따라 분리\n",
    "# 숫자형 분리 pd.api.types.is_numeric_dtype\n",
    "con_columns = []\n",
    "cat_columns = []\n",
    "\n",
    "for column in concat_select.columns:\n",
    "    if pd.api.types.is_numeric_dtype(concat_select[column]):\n",
    "        con_columns.append(column)\n",
    "    else:\n",
    "        cat_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ee3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#상관관계 기반으로 중복 feature 쌍 탐지 및 삭제 후보 추천\n",
    "\n",
    "# 연속형 변수만 추출\n",
    "numeric_cols = con_columns  # ← 너가 나눠둔 연속형 변수 리스트\n",
    "\n",
    "# 상관관계 행렬 (절댓값 기준)\n",
    "corr_matrix = concat_select[numeric_cols].corr().abs()\n",
    "\n",
    "# 상삼각 행렬로 중복 제거\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# 상관계수 0.9 초과인 변수쌍 추출\n",
    "high_corr_pairs = [(col, row, upper.loc[row, col])\n",
    "                   for col in upper.columns\n",
    "                   for row in upper.index\n",
    "                   if pd.notnull(upper.loc[row, col]) and upper.loc[row, col] > 0.7]\n",
    "\n",
    "# 출력\n",
    "for col1, col2, score in sorted(high_corr_pairs, key=lambda x: -x[2]):\n",
    "    print(f\"🔁 {col1} ↔ {col2} : 상관계수 = {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전용면적별세대현황 pca\n",
    "\n",
    "pca_cols = [\n",
    "    'k-전용면적별세대현황(60㎡이하)',\n",
    "    'k-전용면적별세대현황(60㎡~85㎡이하)',\n",
    "    'k-85㎡~135㎡이하']\n",
    "pca_data = concat_select[pca_cols].fillna(0)  # 혹시 모르니 결측 0으로 대체\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_pca_data = scaler.fit_transform(pca_data)\n",
    "\n",
    "# 2개 성분으로 축소\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)  \n",
    "pca_components = pca.fit_transform(scaled_pca_data)\n",
    "\n",
    "# PCA 설명력 보기\n",
    "print(pca.explained_variance_ratio_)  # 예: [0.83, 0.16]\n",
    "\n",
    "# PCA 결과 저장\n",
    "concat_select[\"세대면적_PCA1\"] = pca_components[:, 0]\n",
    "concat_select[\"세대면적_PCA2\"] = pca_components[:, 1]\n",
    "\n",
    "# 원본 feature 제거\n",
    "concat_select.drop(columns=pca_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56054295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속형 변수 상관관계 기반으로 중복의 의미를 갖는 값 삭제\n",
    "\n",
    "drop_cols = ['k-관리비부과면적','k-연면적','k-전체동수']\n",
    "concat_select.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b77647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속형 변수 동 단위 평균으로 결측치 채우기\n",
    "# 동이 없으면 구, 구가 없으면 전체 평균으로 채우기\n",
    "# target은 건들지 말아보자\n",
    "\n",
    "concat_select['구'] = concat_select['시군구'].str.split().str[1]\n",
    "concat_select['동'] = concat_select['시군구'].str.split().str[2]\n",
    "\n",
    "impute_targets = ['건축면적', '주차대수', '좌표X', '좌표Y', 'k-주거전용면적', 'k-전체세대수']\n",
    "\n",
    "for col in impute_targets:\n",
    "    # 1차: 동 단위 평균\n",
    "    concat_select[col] = concat_select.groupby('동')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    # 2차: 구 단위 평균 (동 평균이 안 되면 여기서)\n",
    "    concat_select[col] = concat_select.groupby('구')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    # 3차: 전체 평균 (구 평균도 안 되면 여기서)\n",
    "    concat_select[col].fillna(concat_select[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8346878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 feature들 관계 보기\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Cramér's V 계산 함수\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix, correction=False)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(k - 1, r - 1))\n",
    "\n",
    "# 범주형 변수 리스트\n",
    "cat_cols = cat_columns2  # 이미 나눈 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크래머스 브이 기준 관계있는 범주형 변수 삭제\n",
    "drop_cat_cols = [\n",
    "    '본번',\n",
    "    '부번',\n",
    "    '도로명',\n",
    "    '단지승인일',\n",
    "    '단지신청일',\n",
    "    'k-세대타입(분양형태)',\n",
    "    'k-관리방식',\n",
    "    'k-난방방식',\n",
    "    'k-복도유형',\n",
    "    '세대전기계약방법',\n",
    "    '경비비관리형태',\n",
    "    '청소비관리형태',\n",
    "    '기타/의무/임대/임의=1/2/3/4',\n",
    "]\n",
    "\n",
    "# 제거 적용\n",
    "concat_select.drop(columns=drop_cat_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391fc447",
   "metadata": {},
   "source": [
    "### 이상치 탐지 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30144e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR로 이상치 탐지\n",
    "def detect_outliers_iqr(df, columns, iqr_scale=1.5):\n",
    "    outlier_summary = []\n",
    "\n",
    "    for col in columns:\n",
    "        if df[col].isnull().all():\n",
    "            continue\n",
    "\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - iqr_scale * IQR\n",
    "        upper_bound = Q3 + iqr_scale * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        outlier_count = outliers.shape[0]\n",
    "        outlier_ratio = outlier_count / df.shape[0] * 100\n",
    "\n",
    "        outlier_summary.append({\n",
    "            '변수': col,\n",
    "            '이상치 개수': outlier_count,\n",
    "            '이상치 비율(%)': round(outlier_ratio, 2)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(outlier_summary).sort_values('이상치 비율(%)', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6499d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca 설명력이 높지도 않고 이상치도 많아서 pca 제거\n",
    "# 원본 k-전용면적별세대현황(60㎡~85㎡이하) 가져오기\n",
    "\n",
    "# 1. PCA로 만든 feature 제거\n",
    "pca_cols = ['세대면적_PCA1', '세대면적_PCA2']\n",
    "concat_select.drop(columns=pca_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# 2. 원본에서 특정 변수만 가져와서 추가\n",
    "selected_feature = 'k-전용면적별세대현황(60㎡~85㎡이하)'\n",
    "concat_select[selected_feature] = concat[selected_feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_select가 아닌 concat에서 가져와서 결측치 확인\n",
    "\n",
    "concat_select['k-전용면적별세대현황(60㎡~85㎡이하)'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f076419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치는 동/구/전체 평균으로 채우기\n",
    "\n",
    "impute2_targets = ['k-전용면적별세대현황(60㎡~85㎡이하)']\n",
    "\n",
    "for col in impute2_targets:\n",
    "    # 1차: 동 단위 평균\n",
    "    concat_select[col] = concat_select.groupby('동')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    # 2차: 구 단위 평균 (동 평균이 안 되면 여기서)\n",
    "    concat_select[col] = concat_select.groupby('구')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "    # 3차: 전체 평균 (구 평균도 안 되면 여기서)\n",
    "    concat_select[col].fillna(concat_select[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f63764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 적용 및 다음 이상치 탐지\n",
    "\n",
    "# 리스트 초기화\n",
    "con_columns_final = []\n",
    "cat_columns_final = []\n",
    "\n",
    "# concat_select 기준으로 분리\n",
    "for col in concat_select.columns:\n",
    "    if pd.api.types.is_numeric_dtype(concat_select[col]):\n",
    "        con_columns_final.append(col)\n",
    "    else:\n",
    "        cat_columns_final.append(col)\n",
    "\n",
    "def detect_outliers_iqr(df, columns, iqr_scale=1.5):\n",
    "    outlier_summary = []\n",
    "\n",
    "    for col in columns:\n",
    "        if df[col].isnull().all():\n",
    "            continue\n",
    "\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - iqr_scale * IQR\n",
    "        upper_bound = Q3 + iqr_scale * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        outlier_count = outliers.shape[0]\n",
    "        outlier_ratio = outlier_count / df.shape[0] * 100\n",
    "\n",
    "        outlier_summary.append({\n",
    "            '변수': col,\n",
    "            '이상치 개수': outlier_count,\n",
    "            '이상치 비율(%)': round(outlier_ratio, 2)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(outlier_summary).sort_values('이상치 비율(%)', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cb2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전용세대별면적PCA 변수 외 이상치 발견값 clip\n",
    "\n",
    "def clip_iqr(df, columns, k=1.5):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - k * IQR\n",
    "        upper = Q3 + k * IQR\n",
    "        df[col] = df[col].clip(lower, upper)\n",
    "    return df\n",
    "\n",
    "clip_cols = ['건축면적', '전용면적', 'k-전용면적별세대현황(60㎡~85㎡이하)', 'k-전체세대수', '주차대수']\n",
    "\n",
    "concat_select = clip_iqr(concat_select, clip_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b804b",
   "metadata": {},
   "source": [
    "### 모델 학습을 위한 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ea07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 다시 train과 test dataset을 분할해줍니다. 위에서 제작해 놓았던 is_test 칼럼을 이용합니다.\n",
    "dt_train = concat_select.query('data==0')\n",
    "dt_test = concat_select.query('data==1')\n",
    "\n",
    "# 이제 is_test 칼럼은 drop해줍니다.\n",
    "dt_train.drop(['data'], axis = 1, inplace=True)\n",
    "dt_test.drop(['data'], axis = 1, inplace=True)\n",
    "print(dt_train.shape, dt_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eafc371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 인코딩\n",
    "# 파생변수 제작으로 추가된 변수들이 존재하기에, 다시한번 연속형과 범주형 칼럼을 분리해주겠습니다.\n",
    "continuous_columns_final = []\n",
    "categorical_columns_final = []\n",
    "\n",
    "for column in dt_train.columns:\n",
    "    if pd.api.types.is_numeric_dtype(dt_train[column]):\n",
    "        continuous_columns_final.append(column)\n",
    "    else:\n",
    "        categorical_columns_final.append(column)\n",
    "\n",
    "print(\"연속형 변수:\", continuous_columns_final)\n",
    "print(\"범주형 변수:\", categorical_columns_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f826c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에서 범주형 변수들을 대상으로 레이블인코딩을 진행해 주겠습니다.\n",
    "\n",
    "# 각 변수에 대한 LabelEncoder를 저장할 딕셔너리\n",
    "label_encoders = {}\n",
    "\n",
    "# Implement Label Encoding\n",
    "for col in tqdm( categorical_columns_final ):\n",
    "    lbl = LabelEncoder()\n",
    "\n",
    "    # Label-Encoding을 fit\n",
    "    lbl.fit( dt_train[col].astype(str) )\n",
    "    dt_train[col] = lbl.transform(dt_train[col].astype(str))\n",
    "    label_encoders[col] = lbl           # 나중에 후처리를 위해 레이블인코더를 저장해주겠습니다.\n",
    "\n",
    "    # Test 데이터에만 존재하는 새로 출현한 데이터를 신규 클래스로 추가해줍니다.\n",
    "    for label in np.unique(dt_test[col]):\n",
    "      if label not in lbl.classes_: # unseen label 데이터인 경우\n",
    "        lbl.classes_ = np.append(lbl.classes_, label) # 미처리 시 ValueError발생하니 주의하세요!\n",
    "\n",
    "    dt_test[col] = lbl.transform(dt_test[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target과 독립변수들을 분리해줍니다.\n",
    "y_train = dt_train['target']\n",
    "X_train = dt_train.drop(['target'], axis=1)\n",
    "\n",
    "# Hold out split을 사용해 학습 데이터와 검증 데이터를 8:2 비율로 나누겠습니다.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=2023)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
