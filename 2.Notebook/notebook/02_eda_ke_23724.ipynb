{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab59052c",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "- RMSE : 23724.4207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install eli5==0.13.0\n",
    "\n",
    "# 한글 폰트 사용을 위한 라이브러리입니다.\n",
    "!apt-get install -y fonts-nanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # ttf 파일이 저장되어 있는 경로\n",
    "    name='NanumBarunGothic')                        # 이 폰트의 원하는 이름 설정\n",
    "fm.fontManager.ttflist.insert(0, fe)              # Matplotlib에 폰트 추가\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # 폰트 설정\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "\n",
    "# utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "# Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d12333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 열 다 보이게 설정\n",
    "pd.set_option('display.max_columns', None)\n",
    "# 행 다 보이게 설정\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636820bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 위해 데이터 합치고 확인\n",
    "\n",
    "train['data'] = 0\n",
    "test['data'] = 1\n",
    "concat = pd.concat([train, test])\n",
    "\n",
    "print(concat.shape)\n",
    "print(concat['data'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 탐색 및 보간\n",
    "\n",
    "# 열 전체를 넣고 스캔하기\n",
    "\n",
    "for col in concat.columns:\n",
    "    nunique = concat[col].nunique(dropna=False)\n",
    "    missing_ratio = concat[col].isna().mean()\n",
    "    missing_count = concat[col].isnull().sum()\n",
    "    col_type = concat.dtypes[col]\n",
    "    print(f\"📌 {col:30} | 데이터타입: {col_type} | 고유값: {nunique:6} | 결측개수: {missing_count} | 결측률: {missing_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치는 아닌데 의미 없는 형식적 값 찾기\n",
    "\n",
    "def detect_fake_nulls(df, suspect_values=['-', ' ', '', '.', '없음', 'nan']):\n",
    "    result = {}\n",
    "    for col in df.columns:\n",
    "        if concat[col].dtype == 'object':\n",
    "            val_counts = concat[col].value_counts(dropna=False)\n",
    "            found = val_counts[val_counts.index.isin(suspect_values)]\n",
    "            if not found.empty:\n",
    "                result[col] = found\n",
    "    return result\n",
    "\n",
    "fake_nulls = detect_fake_nulls(concat)\n",
    "for col, vals in fake_nulls.items():\n",
    "    print(f\"🔎 {col} 컬럼에서 의미 없는 값 발견:\")\n",
    "    print(vals)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27535b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의미없는 값 결측치로 인식시키고 결측률 보기\n",
    "# 열 전체를 넣고 스캔하기\n",
    "\n",
    "for col in concat.columns:\n",
    "    nunique = concat[col].nunique(dropna=False)\n",
    "    missing_ratio = concat[col].isna().mean()\n",
    "    missing_count = concat[col].isnull().sum()\n",
    "    col_type = concat.dtypes[col]\n",
    "    print(f\"📌 {col:30} | 데이터타입: {col_type} | 고유값: {nunique:6} | 결측개수: {missing_count} | 결측률: {missing_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측 채우고 info 본 후에 데이터 타입 변환\n",
    "# 본번, 부번의 경우 float로 되어있지만 범주형 변수의 의미를 가지므로 object(string) 형태로 바꾸어주고 아래 작업을 진행하겠습니다.\n",
    "concat_select['본번'] = concat_select['본번'].astype('str')\n",
    "concat_select['부번'] = concat_select['부번'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_summary(df, columns):\n",
    "    result = pd.DataFrame({\n",
    "        '결측 개수': df[columns].isnull().sum(),\n",
    "        '결측 비율(%)': df[columns].isnull().mean() * 100\n",
    "    })\n",
    "    return result[result['결측 개수'] > 0].sort_values('결측 비율(%)', ascending=False)\n",
    "\n",
    "print(\"📊 연속형 변수 결측치 요약\")\n",
    "display(null_summary(concat_select, con_columns))\n",
    "\n",
    "print(\"📊 범주형 변수 결측치 요약\")\n",
    "display(null_summary(concat_select, cat_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 탐지 및 처리 전 연속형 변수 상관관계 보기\n",
    "\n",
    "# 1. 수치형 변수만 선택\n",
    "numeric_cols = concat_select.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# 2. 상관관계 계산\n",
    "corr = concat_select[numeric_cols].corr()\n",
    "\n",
    "# 3. 시각화\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title(\"📊 수치형 변수 간 상관관계\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f63653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 기반으로 중복 feature 쌍 탐지 및 삭제 후보 추천\n",
    "\n",
    "# 연속형 변수만 추출\n",
    "numeric_cols = con_columns  # ← 너가 나눠둔 연속형 변수 리스트\n",
    "\n",
    "# 상관관계 행렬 (절댓값 기준)\n",
    "corr_matrix = concat_select[numeric_cols].corr().abs()\n",
    "\n",
    "# 상삼각 행렬로 중복 제거\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# 상관계수 0.9 초과인 변수쌍 추출\n",
    "high_corr_pairs = [(col, row, upper.loc[row, col])\n",
    "                   for col in upper.columns\n",
    "                   for row in upper.index\n",
    "                   if pd.notnull(upper.loc[row, col]) and upper.loc[row, col] > 0.7]\n",
    "\n",
    "# 출력\n",
    "for col1, col2, score in sorted(high_corr_pairs, key=lambda x: -x[2]):\n",
    "    print(f\"🔁 {col1} ↔ {col2} : 상관계수 = {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1442e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관관계 보고 pca와 제거 진행 후 리스트 초기화 및 지정\n",
    "# 범주형 변수 관계 보기 전 확인\n",
    "# 숫자형 분리 pd.api.types.is_numeric_dtype\n",
    "con_columns2 = []\n",
    "cat_columns2 = []\n",
    "\n",
    "for column in concat_select.columns:\n",
    "    if pd.api.types.is_numeric_dtype(concat_select[column]):\n",
    "        con_columns2.append(column)\n",
    "    else:\n",
    "        cat_columns2.append(column)\n",
    "\n",
    "print(\"연속형 변수:\", con_columns2)\n",
    "print(\"범주형 변수:\", cat_columns2)\n",
    "\n",
    "def null_summary(df, columns):\n",
    "    result = pd.DataFrame({\n",
    "        '결측 개수': df[columns].isnull().sum(),\n",
    "        '결측 비율(%)': df[columns].isnull().mean() * 100\n",
    "    })\n",
    "    return result[result['결측 개수'] > 0].sort_values('결측 비율(%)', ascending=False)\n",
    "\n",
    "print(\"📊 연속형 변수 결측치 요약\")\n",
    "display(null_summary(concat_select, con_columns2))\n",
    "\n",
    "print(\"📊 범주형 변수 결측치 요약\")\n",
    "display(null_summary(concat_select, cat_columns2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 feature들 관계 보기\n",
    "# 보기 전 결측값은 임의로 채움\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Cramér's V 계산 함수\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix, correction=False)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(k - 1, r - 1))\n",
    "\n",
    "# 범주형 변수 리스트\n",
    "cat_cols = cat_columns2  # 이미 나눈 리스트\n",
    "\n",
    "# 결과 저장용 매트릭스\n",
    "cramer_matrix = pd.DataFrame(index=cat_cols, columns=cat_cols)\n",
    "\n",
    "for col1 in cat_cols:\n",
    "    for col2 in cat_cols:\n",
    "        if col1 == col2:\n",
    "            cramer_matrix.loc[col1, col2] = 1.0\n",
    "        else:\n",
    "            try:\n",
    "                cramer_matrix.loc[col1, col2] = cramers_v(concat_select[col1], concat_select[col2])\n",
    "            except:\n",
    "                cramer_matrix.loc[col1, col2] = np.nan\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cramer_matrix.astype(float), cmap='coolwarm', annot=False)\n",
    "plt.title(\"범주형 변수 간 Cramér's V (상관관계 유사도)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니크 값이 낮으면 값이 다양하지 않아 유사성이 높을 수 있다고 함\n",
    "# 변주형 중 unique값이 낮은 것\n",
    "\n",
    "for col in cat_columns2:\n",
    "    print(f\"{col}: {concat_select[col].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c378b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크래머스 브이 수치로 보기\n",
    "\n",
    "threshold = 0.8\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(cat_cols)):\n",
    "    for j in range(i + 1, len(cat_cols)):\n",
    "        col1, col2 = cat_cols[i], cat_cols[j]\n",
    "        val = cramer_matrix.loc[col1, col2]\n",
    "        if pd.notnull(val) and float(val) >= threshold:\n",
    "            high_corr_pairs.append((col1, col2, float(val)))\n",
    "\n",
    "for col1, col2, score in sorted(high_corr_pairs, key=lambda x: -x[2]):\n",
    "    print(f\"🔁 {col1} ↔ {col2} : Cramér's V = {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bbc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 확인\n",
    "# 빈 리스트 초기화\n",
    "con_columns_final = []\n",
    "cat_columns_final = []\n",
    "\n",
    "# 현재 concat_filtered 기준으로 데이터타입 분리\n",
    "for col in concat_select.columns:\n",
    "    if pd.api.types.is_numeric_dtype(concat_select[col]):\n",
    "        con_columns_final.append(col)\n",
    "    else:\n",
    "        cat_columns_final.append(col)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"✅ 연속형 변수:\", con_columns_final)\n",
    "print(\"✅ 범주형 변수:\", cat_columns_final)\n",
    "print(f\"📊 총 연속형 변수 개수: {len(con_columns_final)}\")\n",
    "print(f\"📁 총 범주형 변수 개수: {len(cat_columns_final)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a915f778",
   "metadata": {},
   "source": [
    "### 파생변수 생성 후 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4267b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_select[['지하철_1000m내_개수', '지하철_1000m내_이름목록', '지하철_최단거리_km','지하철_최단거리_역명']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지하철과 버스 데이터로 파생변수 생성 후 전체 살피기\n",
    "\n",
    "concat_select.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d857a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트 초기화\n",
    "con_columns_final = []\n",
    "cat_columns_final = []\n",
    "\n",
    "# concat_select 기준으로 분리\n",
    "for col in concat_select.columns:\n",
    "    if pd.api.types.is_numeric_dtype(concat_select[col]):\n",
    "        con_columns_final.append(col)\n",
    "    else:\n",
    "        cat_columns_final.append(col)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"✅ 연속형 변수:\", con_columns_final)\n",
    "print(\"✅ 범주형 변수:\", cat_columns_final)\n",
    "print(f\"📊 총 연속형 변수 개수: {len(con_columns_final)}\")\n",
    "print(f\"📁 총 범주형 변수 개수: {len(cat_columns_final)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가한 변수들 상관관계 보기\n",
    "\n",
    "correlation_with_target = concat_select[con_columns_final].corr()['target'].sort_values(ascending=False)\n",
    "print(correlation_with_target)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(concat_select[con_columns_final].corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"연속형 변수 상관관계 히트맵\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec87464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가한 변수(범주형) 관계 보기\n",
    "\n",
    "# 범주형 feature들 관계 보기\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Cramér's V 계산 함수\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix, correction=False)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(k - 1, r - 1))\n",
    "\n",
    "# 범주형 변수 리스트\n",
    "cat_cols = cat_columns2 = cat_columns_final  # 이미 나눈 리스트\n",
    "\n",
    "# 결과 저장용 매트릭스\n",
    "cramer_matrix = pd.DataFrame(index=cat_cols, columns=cat_cols)\n",
    "\n",
    "for col1 in cat_cols:\n",
    "    for col2 in cat_cols:\n",
    "        if col1 == col2:\n",
    "            cramer_matrix.loc[col1, col2] = 1.0\n",
    "        else:\n",
    "            try:\n",
    "                cramer_matrix.loc[col1, col2] = cramers_v(concat_select[col1], concat_select[col2])\n",
    "            except:\n",
    "                cramer_matrix.loc[col1, col2] = np.nan\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cramer_matrix.astype(float), cmap='coolwarm', annot=False)\n",
    "plt.title(\"범주형 변수 간 Cramér's V (상관관계 유사도)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48884b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(cat_cols)):\n",
    "    for j in range(i + 1, len(cat_cols)):\n",
    "        col1, col2 = cat_cols[i], cat_cols[j]\n",
    "        val = cramer_matrix.loc[col1, col2]\n",
    "        if pd.notnull(val) and float(val) >= threshold:\n",
    "            high_corr_pairs.append((col1, col2, float(val)))\n",
    "\n",
    "for col1, col2, score in sorted(high_corr_pairs, key=lambda x: -x[2]):\n",
    "    print(f\"🔁 {col1} ↔ {col2} : Cramér's V = {score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
